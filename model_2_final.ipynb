{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prudhvi0520/DataminingAssign1/blob/main/model_2_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3HA22kaQdh7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56885e9-71f8-4997-ee0a-c7b67f4d66aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.9/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.9/dist-packages (from livelossplot) (2.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (4.5.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (8.4.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (6.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (23.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (4.39.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->livelossplot) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/final/final/images.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/images\")\n",
        "zip_ref.close()\n",
        "!pip install livelossplot\n",
        "import os \n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "import tensorflow as tf\n",
        "from livelossplot.tf_keras import PlotLossesCallback\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ped4p7Ridh7b",
        "outputId": "8e38c6b6-f823-4739-e244-aa027b02432a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Training set description --------------\n",
            "S.No.\tSample Count\tClass\t\n",
            "1\t436\t\tdisgust\n",
            "2\t4982\t\tneutral\n",
            "3\t7164\t\thappy\n",
            "4\t3205\t\tsurprise\n",
            "5\t4103\t\tfear\n",
            "6\t4938\t\tsad\n",
            "7\t3993\t\tangry\n",
            "\n",
            "--------- Validation set description --------------\n",
            "S.No.\tSample Count\tClass\t\n",
            "1\t111\t\tdisgust\n",
            "2\t1216\t\tneutral\n",
            "3\t1825\t\thappy\n",
            "4\t797\t\tsurprise\n",
            "5\t1018\t\tfear\n",
            "6\t1139\t\tsad\n",
            "7\t960\t\tangry\n"
          ]
        }
      ],
      "source": [
        "# understanding the dataset structure\n",
        "data_dir = '../images/images/'\n",
        "training_path = '/content/images/images/images/train/'\n",
        "validation_path = '/content/images/images/images/validation/'\n",
        "\n",
        "\n",
        "# Training classes\n",
        "print(\"--------- Training set description --------------\")\n",
        "print(\"S.No.\\tSample Count\\tClass\\t\")\n",
        "# Printing distribution of each class in training set\n",
        "for (i,expression) in enumerate(os.listdir(training_path)):\n",
        "    print(str(i+1)+ \"\\t\"+ str(len(os.listdir(training_path + expression))) + \"\\t\\t\" + expression )\n",
        "    \n",
        "\n",
        "# Validation classes\n",
        "print(\"\\n--------- Validation set description --------------\")\n",
        "print(\"S.No.\\tSample Count\\tClass\\t\")\n",
        "# Printing distribution of each class in training set\n",
        "for (i,expression) in enumerate(os.listdir(validation_path)):\n",
        "    print(str(i+1)+ \"\\t\"+ str(len(os.listdir(validation_path + expression))) + \"\\t\\t\" + expression )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mT9fjJNkdh7b"
      },
      "outputs": [],
      "source": [
        "def create_dataset(main_path):\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    df = {\"img\":[],\"img_class\":[]}\n",
        "    for class_names in os.listdir(main_path):\n",
        "        for img_path in glob.glob(f\"{main_path}/{class_names}/*\"):\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (48, 48))\n",
        "            img = img[..., np.newaxis] / 255.0         \n",
        "            df[\"img\"].append(img)\n",
        "            df[\"img_class\"].append(class_names)\n",
        "    df[\"img\"] = np.array(df[\"img\"], dtype='float32')\n",
        "    df[\"img_class\"] = label_encoder.fit_transform(df[\"img_class\"])\n",
        "    df[\"img_class\"] = tf.keras.utils.to_categorical(df[\"img_class\"])\n",
        "    return df[\"img\"],df[\"img_class\"]\n",
        "    \n",
        "training_dataset, training_labels = create_dataset(training_path[:len(training_path)-1])\n",
        "validation_dataset, validation_labels  = create_dataset(validation_path[:len(validation_path)-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VueY_wHGdh7b"
      },
      "outputs": [],
      "source": [
        "# Defining constants \n",
        "BATCH_SIZE = 64\n",
        "img_channel = 3\n",
        "LEARNING_RATE = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vWPBvW5fdh7c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='reflect'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn3gRPKldh7d"
      },
      "source": [
        "<h3>Building Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQH7zfEVdh7d",
        "outputId": "19b30052-af85-4a4e-8565-457ee7593724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 46, 46, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " activation (Activation)     (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 21, 21, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               819328    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 839,431\n",
            "Trainable params: 839,239\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Dense,  Dropout,Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 1 - Convolution\n",
        "model.add(Conv2D(32, (3, 3),  input_shape=(48, 48, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer 1st layer\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "opt = Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1yqpmppydh7f"
      },
      "outputs": [],
      "source": [
        "early_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",patience=3,mode=\"auto\")\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_weights.h5\",verbose=1,save_best_only=True,save_weights_only = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1y2TL3-dh7f",
        "outputId": "16a510d9-a409-4630-c127-329621db4338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "419/451 [==========================>...] - ETA: 10s - loss: 1.8706 - accuracy: 0.2206"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    data_augmentation.flow(training_dataset, training_labels, batch_size=BATCH_SIZE),    \n",
        "    epochs=100,\n",
        "    callbacks=[PlotLossesCallback(),checkpoint, early_stopping],\n",
        "    validation_data=(validation_dataset,validation_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhaQhnVJdh7g"
      },
      "outputs": [],
      "source": [
        "# Save Model\n",
        "model.save(\"FacialExpressionModel.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}